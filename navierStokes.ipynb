{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PFE: solution of differential equations PDEs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PART 1 : solving partial differential equations using deep learning 'Neural networks' with SciANN library**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **The second type of equations is Navier-Stokes equation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * **Importing libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- SCIANN 0.6.5.1 ---------------------- \n",
      "For details, check out our review paper and the documentation at: \n",
      " +  \"https://www.sciencedirect.com/science/article/pii/S0045782520307374\", \n",
      " +  \"https://arxiv.org/abs/2005.08803\", \n",
      " +  \"https://www.sciann.com\". \n",
      "\n",
      " Need support or would like to contribute, please join sciann`s slack group: \n",
      " +  \"https://join.slack.com/t/sciann/shared_invite/zt-ne1f5jlx-k_dY8RGo3ZreDXwz0f~CeA\" \n",
      " \n",
      "TensorFlow Version: 2.5.3 \n",
      "Python Version: 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sciann as sn\n",
    "from scipy import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__header__\n",
      "__version__\n",
      "__globals__\n",
      "X_star\n",
      "t\n",
      "U_star\n",
      "p_star\n"
     ]
    }
   ],
   "source": [
    "df = io.loadmat('cylinder_nektar_wake')\n",
    "for key, value in df.items() :\n",
    "    print(key) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_star_shape : (5000, 2)\n",
      "t_shape : (200, 1)\n",
      "u_star_shape : (5000, 2, 200)\n",
      "p_star_shape : (5000, 200)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"x_star_shape : {df['X_star'].shape}\")\n",
    "print(f\"t_shape : {df['t'].shape}\")\n",
    "print(f\"u_star_shape : {df['U_star'].shape}\")\n",
    "print(f\"p_star_shape : {df['p_star'].shape}\")\n",
    "idx = np.random.choice(1000000, 5000, replace=False)\n",
    "df['U_star'][:, 0, :].flatten()[idx, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(n_data= 5000, random=True):\n",
    "    \n",
    "    U_star = df['U_star'] \n",
    "    P_star = df['p_star'] \n",
    "    t_star = df['t'] \n",
    "    X_star = df['X_star'] \n",
    "    \n",
    "    N = X_star.shape[0] # 5000\n",
    "    T = t_star.shape[0] # 200\n",
    "    \n",
    "    # Rearrange data\n",
    "    XX = np.tile(X_star[:,0:1], (1,T)) # it shape 5000 x 200\n",
    "    YY = np.tile(X_star[:,1:2], (1,T)) # it shape 5000 x 200\n",
    "    TT = np.tile(t_star, (1,N)).T # it shape 5000 x 200\n",
    "    \n",
    "    UU = U_star[:,0,:] # it shape 5000 x 200\n",
    "    VV = U_star[:,1,:] # it shape 5000 x 200\n",
    "    PP = P_star # it shape 5000 x 200\n",
    "    \n",
    "    # Pick random df.\n",
    "    if random:\n",
    "        idx = np.random.choice(N*T, n_data, replace=False) # choice a 5000 features from N*T = 1000000 features\n",
    "    else:\n",
    "        idx = np.arange(0, N*T)\n",
    "    \n",
    "    x = XX.flatten()[idx,None] # NT x 1  ===> 5000 * 1\n",
    "    y = YY.flatten()[idx,None] # NT x 1\n",
    "    t = TT.flatten()[idx,None] # NT x 1\n",
    "    \n",
    "    u = UU.flatten()[idx,None] # NT x 1 # flatten() reshape array from n-dim to one dim\n",
    "    v = VV.flatten()[idx,None] # NT x 1\n",
    "    p = PP.flatten()[idx,None] # NT x 1\n",
    " \n",
    "    return (x,y,t,u,v,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, t_train, u_train, v_train, p_train = prepareData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Step 2: Setting up the neural network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sn.Variable('x', dtype='float64')\n",
    "t = sn.Variable('t', dtype='float64')\n",
    "y = sn.Variable('y', dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the solutions variable\n",
    "p = sn.Functional('p', [x,y,t], 8*[20], 'tanh')\n",
    "psi = sn.Functional('psi', [x,y,t], 8*[20], 'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = sn.diff(psi, y)\n",
    "v = -sn.diff(psi, x)\n",
    "\n",
    "p_x = sn.diff(p, x)\n",
    "p_y = sn.diff(p, y)\n",
    "\n",
    "u_t = sn.diff(u, t)\n",
    "u_x = sn.diff(u, x)\n",
    "u_xx = sn.diff(u, x, order=2)\n",
    "u_y = sn.diff(u, y)\n",
    "u_yy = sn.diff(u, y, order=2)\n",
    "\n",
    "v_t = sn.diff(v, t)\n",
    "v_x = sn.diff(v, x)\n",
    "v_xx = sn.diff(v, x, order=2)\n",
    "v_y = sn.diff(v, y)\n",
    "v_yy = sn.diff(v, y, order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda1 = sn.Parameter(np.random.rand(), inputs=[x,y,t], name=\"lambda1\")\n",
    "lambda2 = sn.Parameter(np.random.rand(), inputs=[x,y,t], name=\"lambda2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tie class to constrain network outputs. constraint: cond1 - cond2 == sol.\n",
    "c1 = sn.Tie(-p_x, u_t+lambda1*(u*u_x+v*u_y)-lambda2*(u_xx+u_yy))\n",
    "c2 = sn.Tie(-p_y, v_t+lambda1*(u*v_x+v*v_y)-lambda2*(v_xx+v_yy))\n",
    "c3 = sn.Data(u_x + v_y)\n",
    "c4 = psi*0.0\n",
    "# Data class to impose to the system.\n",
    "d1 = sn.Data(u)\n",
    "d2 = sn.Data(v)\n",
    "d3 = sn.Data(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "# Define the optimization model (set of inputs and constraints)\n",
    "model = sn.SciModel(\n",
    "    inputs=[x, y, t],\n",
    "    targets=[d1, d2, d3, c1, c2, c3, c4],\n",
    "    loss_func=\"mse\",\n",
    "    plot_to_file='NS-Model2.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 5000 \n",
      "Batch size: 100 \n",
      "Total batches: 50 \n",
      "\n",
      "Epoch 1/100\n",
      "50/50 [==============================] - 72s 66ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.5546 - Grad__loss: 0.4191 - mul_loss: 0.0874 - p_loss: 0.0119 - sub_2_loss: 0.0224 - sub_4_loss: 0.0138 - add_7_loss: 1.3206e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 72.4704100.0000 - loss: 0.9142 - Grad__loss: 0.8141 - mul_loss: 0.0702 - p_loss: 0.0244 - sub_2_loss: 0.0027 - sub_4_loss: 0.0027 - add_7_\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 3s 64ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.2447 - Grad__loss: 0.1308 - mul_loss: 0.0761 - p_loss: 0.0091 - sub_2_loss: 0.0193 - sub_4_loss: 0.0093 - add_7_loss: 2.4483e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 3.192000.0000 - loss: 0.2948 - Grad__loss: 0.1757 - mul_loss: 0.0785 - p_loss: 0.0096 - sub_2_loss: 0.0196 - sub_4_loss: 0.0114 - add_7_los\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 3s 52ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.1794 - Grad__loss: 0.0746 - mul_loss: 0.0700 - p_loss: 0.0088 - sub_2_loss: 0.0193 - sub_4_loss: 0.0067 - add_7_loss: 2.9327e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.5962: 100.0000 - loss: 0.1814 - Grad__loss: 0.0761 - mul_loss: 0.0711 - p_loss: 0.0087 - sub_2_loss: 0.0189 - sub_4_loss: 0.0065 - add_7_loss: 2.8196e-33 - mul_12_loss: 0.0000e\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 2s 33ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.1502 - Grad__loss: 0.0564 - mul_loss: 0.0667 - p_loss: 0.0074 - sub_2_loss: 0.0144 - sub_4_loss: 0.0054 - add_7_loss: 3.4409e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.7013\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.1368 - Grad__loss: 0.0512 - mul_loss: 0.0645 - p_loss: 0.0063 - sub_2_loss: 0.0100 - sub_4_loss: 0.0048 - add_7_loss: 4.1591e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9013\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 4s 79ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.1284 - Grad__loss: 0.0485 - mul_loss: 0.0626 - p_loss: 0.0056 - sub_2_loss: 0.0069 - sub_4_loss: 0.0048 - add_7_loss: 4.4678e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 3.9317\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 4s 66ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.1204 - Grad__loss: 0.0439 - mul_loss: 0.0611 - p_loss: 0.0056 - sub_2_loss: 0.0052 - sub_4_loss: 0.0046 - add_7_loss: 5.2910e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 3.5957: 100.0000 - loss: 0.1222 - Grad__loss: 0.0455 - mul_loss: 0.0608 - p_loss: 0.0054 - sub_2_loss: 0.0056 - sub_4_loss: 0.0048 - add_7_loss: 5.3306e-33 - mul_12_l\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 3s 68ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.1163 - Grad__loss: 0.0425 - mul_loss: 0.0596 - p_loss: 0.0054 - sub_2_loss: 0.0041 - sub_4_loss: 0.0046 - add_7_loss: 5.5394e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 3.395000.0000 - loss: 0.1225 - Grad__loss: 0.0454 - mul_loss: 0.0624 - p_loss: 0.0057 - sub_2_loss: 0.0042 - sub_4_loss: 0.0049 - add_7_lo\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 3s 67ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.1126 - Grad__loss: 0.0414 - mul_loss: 0.0579 - p_loss: 0.0055 - sub_2_loss: 0.0034 - sub_4_loss: 0.0044 - add_7_loss: 6.3254e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 3.3445\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 3s 56ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.1069 - Grad__loss: 0.0377 - mul_loss: 0.0561 - p_loss: 0.0056 - sub_2_loss: 0.0031 - sub_4_loss: 0.0044 - add_7_loss: 6.1594e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.8161: 100.0000 - loss: 0.1080 - Grad__loss: 0.0383 - mul_loss: 0.0567 - p_loss: 0.0055 - sub_2_loss: 0.0031 - sub_4_loss: 0.0044 - add_7_loss: 6.2081e-33 - mul_12_loss: 0.000\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 2s 42ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.1008 - Grad__loss: 0.0342 - mul_loss: 0.0539 - p_loss: 0.0054 - sub_2_loss: 0.0029 - sub_4_loss: 0.0044 - add_7_loss: 6.6480e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.0941\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 2s 44ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0952 - Grad__loss: 0.0312 - mul_loss: 0.0520 - p_loss: 0.0053 - sub_2_loss: 0.0026 - sub_4_loss: 0.0040 - add_7_loss: 6.4497e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.2350\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 2s 44ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0891 - Grad__loss: 0.0275 - mul_loss: 0.0503 - p_loss: 0.0054 - sub_2_loss: 0.0023 - sub_4_loss: 0.0037 - add_7_loss: 6.9037e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.3312\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 4s 69ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0853 - Grad__loss: 0.0252 - mul_loss: 0.0493 - p_loss: 0.0053 - sub_2_loss: 0.0021 - sub_4_loss: 0.0034 - add_7_loss: 7.1335e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 3.5440: 100.0000 - loss: 0.0848 - Grad__loss: 0.0250 - mul_loss: 0.0491 - p_loss: 0.0053 - sub_2_loss: 0.0021 - sub_4_loss: 0.0033 - add_7_loss: 7.0714e-33 - mul_12_loss: 0\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 3s 64ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0856 - Grad__loss: 0.0262 - mul_loss: 0.0488 - p_loss: 0.0052 - sub_2_loss: 0.0021 - sub_4_loss: 0.0033 - add_7_loss: 7.4501e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 3.186800.0000 - loss: 0.0856 - Grad__loss: 0.0255 - mul_loss: 0.0497 - p_loss: 0.0047 - sub_2_loss: 0.0021 - sub_4_loss: 0.0035 - add_7_loss: 7.9156e-33 - mul - ETA: 2s - batch: 7.5000 - size: 100.0000 - loss: 0.0857 - Grad__loss: 0.0265 - mul_loss: 0.0485 - p_loss: 0.0051 - sub_2_loss: 0.0021 - sub_4_loss: 0.0035 - add_7_loss: \n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 3s 51ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0835 - Grad__loss: 0.0248 - mul_loss: 0.0482 - p_loss: 0.0051 - sub_2_loss: 0.0021 - sub_4_loss: 0.0033 - add_7_loss: 6.9009e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.5998: 100.0000 - loss: 0.0836 - Grad__loss: 0.0255 - mul_loss: 0.0476 - p_loss: 0.0053 - sub_2_loss: 0.0021 - sub_4_loss: 0.0031 - add_7_loss: 6.9220e-33 - mul_12_l\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 3s 60ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0810 - Grad__loss: 0.0229 - mul_loss: 0.0476 - p_loss: 0.0051 - sub_2_loss: 0.0022 - sub_4_loss: 0.0033 - add_7_loss: 7.0956e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 3.0363\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 2s 49ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0804 - Grad__loss: 0.0224 - mul_loss: 0.0473 - p_loss: 0.0050 - sub_2_loss: 0.0022 - sub_4_loss: 0.0034 - add_7_loss: 8.0411e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.4421\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 2s 46ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0794 - Grad__loss: 0.0219 - mul_loss: 0.0468 - p_loss: 0.0049 - sub_2_loss: 0.0022 - sub_4_loss: 0.0036 - add_7_loss: 8.1890e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.3263\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 2s 45ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0783 - Grad__loss: 0.0212 - mul_loss: 0.0465 - p_loss: 0.0050 - sub_2_loss: 0.0021 - sub_4_loss: 0.0034 - add_7_loss: 8.2272e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.2438\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 2s 47ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0776 - Grad__loss: 0.0211 - mul_loss: 0.0463 - p_loss: 0.0048 - sub_2_loss: 0.0021 - sub_4_loss: 0.0034 - add_7_loss: 8.2340e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.3272\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 2s 44ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0768 - Grad__loss: 0.0206 - mul_loss: 0.0460 - p_loss: 0.0048 - sub_2_loss: 0.0020 - sub_4_loss: 0.0034 - add_7_loss: 8.9288e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.2119\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 3s 55ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0754 - Grad__loss: 0.0198 - mul_loss: 0.0454 - p_loss: 0.0048 - sub_2_loss: 0.0021 - sub_4_loss: 0.0034 - add_7_loss: 9.0117e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.7691 100.0000 - loss: 0.0712 - Grad__loss: 0.0170 - mul_loss: 0.0435 - p_loss: 0.0051 - sub_2_loss: 0.0023 - sub_4_loss: 0.0033 - \n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 2s 48ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0754 - Grad__loss: 0.0200 - mul_loss: 0.0451 - p_loss: 0.0048 - sub_2_loss: 0.0021 - sub_4_loss: 0.0034 - add_7_loss: 8.9964e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.4931\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 2s 45ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0745 - Grad__loss: 0.0197 - mul_loss: 0.0447 - p_loss: 0.0047 - sub_2_loss: 0.0020 - sub_4_loss: 0.0033 - add_7_loss: 9.2655e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.3657\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 2s 42ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0734 - Grad__loss: 0.0191 - mul_loss: 0.0442 - p_loss: 0.0046 - sub_2_loss: 0.0021 - sub_4_loss: 0.0034 - add_7_loss: 9.5778e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.0959\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 2s 47ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0728 - Grad__loss: 0.0190 - mul_loss: 0.0439 - p_loss: 0.0046 - sub_2_loss: 0.0020 - sub_4_loss: 0.0032 - add_7_loss: 9.7924e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.4330\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 3s 65ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0713 - Grad__loss: 0.0182 - mul_loss: 0.0434 - p_loss: 0.0046 - sub_2_loss: 0.0021 - sub_4_loss: 0.0032 - add_7_loss: 9.5045e-33 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 3.3663\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 3s 60ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0718 - Grad__loss: 0.0189 - mul_loss: 0.0431 - p_loss: 0.0045 - sub_2_loss: 0.0020 - sub_4_loss: 0.0031 - add_7_loss: 1.0455e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 3.0078\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 3s 62ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0706 - Grad__loss: 0.0181 - mul_loss: 0.0427 - p_loss: 0.0046 - sub_2_loss: 0.0020 - sub_4_loss: 0.0032 - add_7_loss: 1.0735e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 3.126400.0000 - loss: 0.0695 - Grad__loss: 0.0179 - mul_loss: 0.0421 - p_loss: 0.0044 - sub_2_loss: 0.0021 - sub_4_loss: 0.0030 \n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 3s 57ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0705 - Grad__loss: 0.0185 - mul_loss: 0.0424 - p_loss: 0.0045 - sub_2_loss: 0.0020 - sub_4_loss: 0.0031 - add_7_loss: 1.0771e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.8533\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 3s 60ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0697 - Grad__loss: 0.0186 - mul_loss: 0.0418 - p_loss: 0.0044 - sub_2_loss: 0.0020 - sub_4_loss: 0.0030 - add_7_loss: 1.0188e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.9989\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 3s 51ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0687 - Grad__loss: 0.0176 - mul_loss: 0.0416 - p_loss: 0.0045 - sub_2_loss: 0.0020 - sub_4_loss: 0.0030 - add_7_loss: 1.0120e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.5434\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 3s 53ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0680 - Grad__loss: 0.0176 - mul_loss: 0.0411 - p_loss: 0.0044 - sub_2_loss: 0.0019 - sub_4_loss: 0.0030 - add_7_loss: 1.1079e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.6490\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 2s 46ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0672 - Grad__loss: 0.0171 - mul_loss: 0.0407 - p_loss: 0.0044 - sub_2_loss: 0.0020 - sub_4_loss: 0.0029 - add_7_loss: 1.1321e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.3027\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 2s 45ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0667 - Grad__loss: 0.0172 - mul_loss: 0.0403 - p_loss: 0.0043 - sub_2_loss: 0.0019 - sub_4_loss: 0.0030 - add_7_loss: 1.1467e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.2347\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0659 - Grad__loss: 0.0169 - mul_loss: 0.0400 - p_loss: 0.0043 - sub_2_loss: 0.0018 - sub_4_loss: 0.0029 - add_7_loss: 1.1576e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.8958\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 4s 74ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0659 - Grad__loss: 0.0172 - mul_loss: 0.0396 - p_loss: 0.0043 - sub_2_loss: 0.0018 - sub_4_loss: 0.0030 - add_7_loss: 1.1604e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 3.689300.0000 - loss: 0.0665 - Grad__loss: 0.0172 - mul_loss: 0.0402 - p_loss: 0.0042 - sub_2_loss: 0.0018 - sub_4_loss: 0.0031 - add_7_loss: 1.2\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 2s 45ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0659 - Grad__loss: 0.0175 - mul_loss: 0.0393 - p_loss: 0.0042 - sub_2_loss: 0.0019 - sub_4_loss: 0.0030 - add_7_loss: 1.1909e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.3009\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 2s 40ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0647 - Grad__loss: 0.0167 - mul_loss: 0.0390 - p_loss: 0.0042 - sub_2_loss: 0.0018 - sub_4_loss: 0.0029 - add_7_loss: 1.1609e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.0031\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0642 - Grad__loss: 0.0167 - mul_loss: 0.0385 - p_loss: 0.0042 - sub_2_loss: 0.0018 - sub_4_loss: 0.0029 - add_7_loss: 1.2531e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9034\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 2s 37ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0643 - Grad__loss: 0.0170 - mul_loss: 0.0383 - p_loss: 0.0041 - sub_2_loss: 0.0019 - sub_4_loss: 0.0029 - add_7_loss: 1.2026e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.8654\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0641 - Grad__loss: 0.0173 - mul_loss: 0.0380 - p_loss: 0.0040 - sub_2_loss: 0.0018 - sub_4_loss: 0.0029 - add_7_loss: 1.2675e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.8989\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 2s 37ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0631 - Grad__loss: 0.0168 - mul_loss: 0.0376 - p_loss: 0.0040 - sub_2_loss: 0.0018 - sub_4_loss: 0.0029 - add_7_loss: 1.2446e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.8841\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0620 - Grad__loss: 0.0158 - mul_loss: 0.0374 - p_loss: 0.0041 - sub_2_loss: 0.0018 - sub_4_loss: 0.0029 - add_7_loss: 1.3083e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9426\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0617 - Grad__loss: 0.0159 - mul_loss: 0.0371 - p_loss: 0.0041 - sub_2_loss: 0.0019 - sub_4_loss: 0.0028 - add_7_loss: 1.2192e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9538\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0611 - Grad__loss: 0.0159 - mul_loss: 0.0365 - p_loss: 0.0040 - sub_2_loss: 0.0019 - sub_4_loss: 0.0028 - add_7_loss: 1.3079e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9754\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 2s 37ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0607 - Grad__loss: 0.0158 - mul_loss: 0.0363 - p_loss: 0.0040 - sub_2_loss: 0.0019 - sub_4_loss: 0.0028 - add_7_loss: 1.3584e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.8730\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 2s 37ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0596 - Grad__loss: 0.0152 - mul_loss: 0.0358 - p_loss: 0.0040 - sub_2_loss: 0.0018 - sub_4_loss: 0.0028 - add_7_loss: 1.3970e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.8835\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0602 - Grad__loss: 0.0162 - mul_loss: 0.0355 - p_loss: 0.0039 - sub_2_loss: 0.0018 - sub_4_loss: 0.0027 - add_7_loss: 1.3502e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9499\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0592 - Grad__loss: 0.0154 - mul_loss: 0.0353 - p_loss: 0.0039 - sub_2_loss: 0.0019 - sub_4_loss: 0.0027 - add_7_loss: 1.3445e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9838\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0590 - Grad__loss: 0.0158 - mul_loss: 0.0348 - p_loss: 0.0038 - sub_2_loss: 0.0018 - sub_4_loss: 0.0027 - add_7_loss: 1.4015e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.8899\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0584 - Grad__loss: 0.0153 - mul_loss: 0.0346 - p_loss: 0.0040 - sub_2_loss: 0.0019 - sub_4_loss: 0.0027 - add_7_loss: 1.4643e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9412\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0577 - Grad__loss: 0.0151 - mul_loss: 0.0344 - p_loss: 0.0037 - sub_2_loss: 0.0019 - sub_4_loss: 0.0025 - add_7_loss: 1.4609e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.0029\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0575 - Grad__loss: 0.0154 - mul_loss: 0.0338 - p_loss: 0.0037 - sub_2_loss: 0.0019 - sub_4_loss: 0.0027 - add_7_loss: 1.4663e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9680\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 2s 37ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0572 - Grad__loss: 0.0152 - mul_loss: 0.0335 - p_loss: 0.0039 - sub_2_loss: 0.0019 - sub_4_loss: 0.0026 - add_7_loss: 1.4072e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9396\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 2s 39ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0562 - Grad__loss: 0.0148 - mul_loss: 0.0332 - p_loss: 0.0038 - sub_2_loss: 0.0019 - sub_4_loss: 0.0026 - add_7_loss: 1.5165e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.0520\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 2s 37ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0558 - Grad__loss: 0.0149 - mul_loss: 0.0326 - p_loss: 0.0038 - sub_2_loss: 0.0018 - sub_4_loss: 0.0027 - add_7_loss: 1.5731e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9220 100.0000 - loss: 0.0596 - Grad__loss: 0.0168 - mul_loss: 0.0344 - p_loss: 0.0040 - sub_2_loss: 0.0018 - sub_4_loss: 0.0026 - add_7_loss: 1.457\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 2s 37ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0558 - Grad__loss: 0.0151 - mul_loss: 0.0325 - p_loss: 0.0038 - sub_2_loss: 0.0018 - sub_4_loss: 0.0026 - add_7_loss: 1.5147e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.8923\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 2s 37ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0553 - Grad__loss: 0.0148 - mul_loss: 0.0321 - p_loss: 0.0038 - sub_2_loss: 0.0019 - sub_4_loss: 0.0027 - add_7_loss: 1.5899e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.8680\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0538 - Grad__loss: 0.0142 - mul_loss: 0.0312 - p_loss: 0.0038 - sub_2_loss: 0.0019 - sub_4_loss: 0.0028 - add_7_loss: 1.6421e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9465\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0530 - Grad__loss: 0.0142 - mul_loss: 0.0307 - p_loss: 0.0036 - sub_2_loss: 0.0018 - sub_4_loss: 0.0027 - add_7_loss: 1.5190e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9643\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 2s 37ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0531 - Grad__loss: 0.0147 - mul_loss: 0.0301 - p_loss: 0.0036 - sub_2_loss: 0.0019 - sub_4_loss: 0.0029 - add_7_loss: 1.5840e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.8580\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0519 - Grad__loss: 0.0143 - mul_loss: 0.0293 - p_loss: 0.0035 - sub_2_loss: 0.0019 - sub_4_loss: 0.0028 - add_7_loss: 1.6800e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9674\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0510 - Grad__loss: 0.0141 - mul_loss: 0.0287 - p_loss: 0.0037 - sub_2_loss: 0.0017 - sub_4_loss: 0.0028 - add_7_loss: 1.5883e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.0059\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0502 - Grad__loss: 0.0140 - mul_loss: 0.0280 - p_loss: 0.0035 - sub_2_loss: 0.0018 - sub_4_loss: 0.0028 - add_7_loss: 1.7031e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.0037\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0499 - Grad__loss: 0.0140 - mul_loss: 0.0277 - p_loss: 0.0035 - sub_2_loss: 0.0019 - sub_4_loss: 0.0028 - add_7_loss: 1.6773e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9837\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 2s 37ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0499 - Grad__loss: 0.0141 - mul_loss: 0.0274 - p_loss: 0.0036 - sub_2_loss: 0.0018 - sub_4_loss: 0.0029 - add_7_loss: 1.7690e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9971\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0483 - Grad__loss: 0.0138 - mul_loss: 0.0265 - p_loss: 0.0036 - sub_2_loss: 0.0018 - sub_4_loss: 0.0027 - add_7_loss: 1.6609e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9358\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0477 - Grad__loss: 0.0134 - mul_loss: 0.0260 - p_loss: 0.0036 - sub_2_loss: 0.0018 - sub_4_loss: 0.0029 - add_7_loss: 1.7545e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9848\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 2s 36ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0465 - Grad__loss: 0.0133 - mul_loss: 0.0252 - p_loss: 0.0034 - sub_2_loss: 0.0018 - sub_4_loss: 0.0028 - add_7_loss: 1.8104e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.8411\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 2s 39ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0458 - Grad__loss: 0.0132 - mul_loss: 0.0248 - p_loss: 0.0034 - sub_2_loss: 0.0017 - sub_4_loss: 0.0028 - add_7_loss: 1.8163e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.0171\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0449 - Grad__loss: 0.0129 - mul_loss: 0.0241 - p_loss: 0.0034 - sub_2_loss: 0.0018 - sub_4_loss: 0.0027 - add_7_loss: 1.9985e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9906\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 2s 37ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0441 - Grad__loss: 0.0127 - mul_loss: 0.0236 - p_loss: 0.0034 - sub_2_loss: 0.0017 - sub_4_loss: 0.0027 - add_7_loss: 2.0748e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9560\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0433 - Grad__loss: 0.0126 - mul_loss: 0.0230 - p_loss: 0.0033 - sub_2_loss: 0.0018 - sub_4_loss: 0.0027 - add_7_loss: 2.0484e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9913\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 2s 37ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0432 - Grad__loss: 0.0131 - mul_loss: 0.0224 - p_loss: 0.0034 - sub_2_loss: 0.0018 - sub_4_loss: 0.0027 - add_7_loss: 1.9843e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.8494\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 2s 37ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0420 - Grad__loss: 0.0122 - mul_loss: 0.0222 - p_loss: 0.0032 - sub_2_loss: 0.0017 - sub_4_loss: 0.0026 - add_7_loss: 1.9661e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9526\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 2s 39ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0416 - Grad__loss: 0.0123 - mul_loss: 0.0216 - p_loss: 0.0033 - sub_2_loss: 0.0018 - sub_4_loss: 0.0026 - add_7_loss: 2.0510e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.0606\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 2s 39ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0421 - Grad__loss: 0.0129 - mul_loss: 0.0215 - p_loss: 0.0032 - sub_2_loss: 0.0019 - sub_4_loss: 0.0027 - add_7_loss: 2.0124e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9590\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 2s 40ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0413 - Grad__loss: 0.0128 - mul_loss: 0.0211 - p_loss: 0.0032 - sub_2_loss: 0.0018 - sub_4_loss: 0.0025 - add_7_loss: 2.0360e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 2.0844\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0391 - Grad__loss: 0.0114 - mul_loss: 0.0204 - p_loss: 0.0030 - sub_2_loss: 0.0018 - sub_4_loss: 0.0024 - add_7_loss: 2.1107e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9519\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0396 - Grad__loss: 0.0119 - mul_loss: 0.0204 - p_loss: 0.0030 - sub_2_loss: 0.0019 - sub_4_loss: 0.0024 - add_7_loss: 2.1356e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9004\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0380 - Grad__loss: 0.0111 - mul_loss: 0.0196 - p_loss: 0.0031 - sub_2_loss: 0.0018 - sub_4_loss: 0.0024 - add_7_loss: 2.1456e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9459\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 2s 37ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0377 - Grad__loss: 0.0114 - mul_loss: 0.0192 - p_loss: 0.0030 - sub_2_loss: 0.0018 - sub_4_loss: 0.0023 - add_7_loss: 2.1465e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9172\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0367 - Grad__loss: 0.0112 - mul_loss: 0.0187 - p_loss: 0.0028 - sub_2_loss: 0.0018 - sub_4_loss: 0.0021 - add_7_loss: 2.3535e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9332\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 2s 37ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0371 - Grad__loss: 0.0111 - mul_loss: 0.0188 - p_loss: 0.0029 - sub_2_loss: 0.0019 - sub_4_loss: 0.0024 - add_7_loss: 2.3639e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.8481\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 2s 37ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0375 - Grad__loss: 0.0118 - mul_loss: 0.0187 - p_loss: 0.0029 - sub_2_loss: 0.0019 - sub_4_loss: 0.0023 - add_7_loss: 2.2734e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9582\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0361 - Grad__loss: 0.0109 - mul_loss: 0.0181 - p_loss: 0.0029 - sub_2_loss: 0.0019 - sub_4_loss: 0.0023 - add_7_loss: 2.3428e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9619\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 2s 37ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0354 - Grad__loss: 0.0107 - mul_loss: 0.0178 - p_loss: 0.0028 - sub_2_loss: 0.0019 - sub_4_loss: 0.0021 - add_7_loss: 2.3568e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9048\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0343 - Grad__loss: 0.0104 - mul_loss: 0.0172 - p_loss: 0.0028 - sub_2_loss: 0.0019 - sub_4_loss: 0.0021 - add_7_loss: 2.4229e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9447\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 2s 37ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0340 - Grad__loss: 0.0102 - mul_loss: 0.0170 - p_loss: 0.0028 - sub_2_loss: 0.0019 - sub_4_loss: 0.0021 - add_7_loss: 2.4624e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9300\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 2s 37ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0348 - Grad__loss: 0.0111 - mul_loss: 0.0169 - p_loss: 0.0027 - sub_2_loss: 0.0019 - sub_4_loss: 0.0022 - add_7_loss: 2.5701e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9327\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 2s 36ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0339 - Grad__loss: 0.0106 - mul_loss: 0.0165 - p_loss: 0.0027 - sub_2_loss: 0.0019 - sub_4_loss: 0.0021 - add_7_loss: 2.7327e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.8072\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 2s 37ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0345 - Grad__loss: 0.0111 - mul_loss: 0.0166 - p_loss: 0.0027 - sub_2_loss: 0.0019 - sub_4_loss: 0.0021 - add_7_loss: 2.5779e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.8579\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 2s 37ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0328 - Grad__loss: 0.0101 - mul_loss: 0.0161 - p_loss: 0.0026 - sub_2_loss: 0.0019 - sub_4_loss: 0.0021 - add_7_loss: 2.6836e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9463\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 2s 37ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0319 - Grad__loss: 0.0099 - mul_loss: 0.0157 - p_loss: 0.0026 - sub_2_loss: 0.0018 - sub_4_loss: 0.0019 - add_7_loss: 2.7505e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9573\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 2s 37ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0329 - Grad__loss: 0.0104 - mul_loss: 0.0159 - p_loss: 0.0026 - sub_2_loss: 0.0020 - sub_4_loss: 0.0020 - add_7_loss: 2.6884e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9553\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 2s 38ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0317 - Grad__loss: 0.0099 - mul_loss: 0.0155 - p_loss: 0.0026 - sub_2_loss: 0.0019 - sub_4_loss: 0.0019 - add_7_loss: 2.6874e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.8860\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 2s 36ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0310 - Grad__loss: 0.0094 - mul_loss: 0.0151 - p_loss: 0.0026 - sub_2_loss: 0.0019 - sub_4_loss: 0.0020 - add_7_loss: 2.7990e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.8321\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 2s 37ms/step - batch: 24.5000 - size: 100.0000 - loss: 0.0315 - Grad__loss: 0.0098 - mul_loss: 0.0151 - p_loss: 0.0027 - sub_2_loss: 0.0019 - sub_4_loss: 0.0020 - add_7_loss: 2.7798e-32 - mul_12_loss: 0.0000e+00 - lr: 0.0010 - time: 1.9419\n"
     ]
    }
   ],
   "source": [
    "training_history = model.train(\n",
    "    [x_train, y_train, t_train], \n",
    "    [u_train, v_train, p_train, 'zeros', 'zeros', 'zeros', 'zeros'], \n",
    "    epochs=100,\n",
    "    batch_size=100,\n",
    "    shuffle=True,\n",
    "    learning_rate=0.001,\n",
    "    reduce_lr_after=100,\n",
    "    stop_loss_value=1e-8,\n",
    "    verbose=1\n",
    "    )\n",
    "    \n",
    "model.save_weights('trained-navier-stokes.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogy(training_history.history['loss'])\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_eval = u.eval(model, [x_train, y_train, t_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YouSsef-pc\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2424: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "source": [
    "u_pred = model.predict([x_train, y_train, t_train], batch_size=None, verbose=0, steps=None)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f58cf6e73e4f029bbe056118fa6dee644f4f9335ebfaaf3e96b0425ab66bc2da"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
